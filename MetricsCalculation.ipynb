{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b0e14e-14c7-42e3-89e9-5db963412610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/5pd3dh6x5l14qp9rwq3glw0w0000gn/T/ipykernel_23939/1168220827.py:89: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025536809/work/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  tensorify = lambda x: torch.Tensor(x.transpose((2, 0, 1))).unsqueeze(0).float().div(255.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True vs False Image SSIM Score: tensor(0.3385)\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    \"\"\"\n",
    "    Generates a list of Tensor values drawn from a gaussian distribution with standard\n",
    "    diviation = sigma and sum of all elements = 1.\n",
    "\n",
    "    Length of list = window_size\n",
    "    \"\"\"    \n",
    "    gauss =  torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, channel=1):\n",
    "\n",
    "    # Generate an 1D tensor containing values sampled from a gaussian distribution\n",
    "    _1d_window = gaussian(window_size=window_size, sigma=1.5).unsqueeze(1)\n",
    "    \n",
    "    # Converting to 2D  \n",
    "    _2d_window = _1d_window.mm(_1d_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "     \n",
    "    window = torch.Tensor(_2d_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "\n",
    "    return window\n",
    "\n",
    "\n",
    "\n",
    "def ssim(img1, img2, val_range, window_size=11, window=None, size_average=True, full=False):\n",
    "\n",
    "    L = val_range # L is the dynamic range of the pixel values (255 for 8-bit grayscale images),\n",
    "\n",
    "    pad = window_size // 2\n",
    "    \n",
    "    try:\n",
    "        _, channels, height, width = img1.size()\n",
    "    except:\n",
    "        channels, height, width = img1.size()\n",
    "\n",
    "    # if window is not provided, init one\n",
    "    if window is None: \n",
    "        real_size = min(window_size, height, width) # window should be atleast 11x11 \n",
    "        window = create_window(real_size, channel=channels).to(img1.device)\n",
    "    \n",
    "    # calculating the mu parameter (locally) for both images using a gaussian filter \n",
    "    # calculates the luminosity params\n",
    "    mu1 = F.conv2d(img1, window, padding=pad, groups=channels)\n",
    "    mu2 = F.conv2d(img2, window, padding=pad, groups=channels)\n",
    "    \n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2 \n",
    "    mu12 = mu1 * mu2\n",
    "\n",
    "    # now we calculate the sigma square parameter\n",
    "    # Sigma deals with the contrast component \n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=pad, groups=channels) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=pad, groups=channels) - mu2_sq\n",
    "    sigma12 =  F.conv2d(img1 * img2, window, padding=pad, groups=channels) - mu12\n",
    "\n",
    "    # Some constants for stability \n",
    "    C1 = (0.01 ) ** 2  # NOTE: Removed L from here (ref PT implementation)\n",
    "    C2 = (0.03 ) ** 2 \n",
    "\n",
    "    contrast_metric = (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
    "    contrast_metric = torch.mean(contrast_metric)\n",
    "\n",
    "    numerator1 = 2 * mu12 + C1  \n",
    "    numerator2 = 2 * sigma12 + C2\n",
    "    denominator1 = mu1_sq + mu2_sq + C1 \n",
    "    denominator2 = sigma1_sq + sigma2_sq + C2\n",
    "\n",
    "    ssim_score = (numerator1 * numerator2) / (denominator1 * denominator2)\n",
    "\n",
    "    if size_average:\n",
    "        ret = ssim_score.mean() \n",
    "    else: \n",
    "        ret = ssim_score.mean(1).mean(1).mean(1)\n",
    "    \n",
    "    if full:\n",
    "        return ret, contrast_metric\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "tensorify = lambda x: torch.Tensor(x.transpose((2, 0, 1))).unsqueeze(0).float().div(255.0)\n",
    "\n",
    "load_images = lambda x: np.asarray(Image.open(x).resize((480, 640)))\n",
    "\n",
    "img1 = load_images(\"./obamatest6.jpg\")\n",
    "\n",
    "img2 = load_images(\"./zucktest3.jpeg\")\n",
    "\n",
    "_img1 = tensorify(img1)\n",
    "_img2 = tensorify(img2)\n",
    "true_vs_false = ssim(_img1, _img2, val_range=255)\n",
    "print(\"True vs False Image SSIM Score:\", true_vs_false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2011aa74-2dfd-4a80-a303-e72242e130d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  0,  0,  ...,  4,  4,  4],\n",
      "          [ 0,  0,  0,  ...,  4,  4,  4],\n",
      "          [ 0,  0,  0,  ...,  4,  4,  4],\n",
      "          ...,\n",
      "          [ 3,  3,  3,  ...,  2,  2,  2],\n",
      "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "          [ 2,  2,  2,  ...,  2,  2,  2]],\n",
      "\n",
      "         [[13, 13, 13,  ...,  0,  0,  0],\n",
      "          [13, 13, 13,  ...,  0,  0,  0],\n",
      "          [13, 13, 13,  ...,  0,  0,  0],\n",
      "          ...,\n",
      "          [ 5,  5,  5,  ...,  1,  1,  1],\n",
      "          [ 4,  4,  4,  ...,  1,  1,  1],\n",
      "          [ 4,  4,  4,  ...,  1,  1,  1]],\n",
      "\n",
      "         [[22, 22, 22,  ..., 17, 17, 17],\n",
      "          [22, 22, 22,  ..., 17, 17, 17],\n",
      "          [22, 22, 22,  ..., 17, 17, 17],\n",
      "          ...,\n",
      "          [18, 18, 18,  ...,  6,  6,  6],\n",
      "          [16, 16, 16,  ...,  6,  6,  6],\n",
      "          [16, 16, 16,  ...,  6,  6,  6]]]], dtype=torch.uint8)\n",
      "tensor([[[[ 0,  0,  0,  ..., 12, 12, 12],\n",
      "          [ 0,  0,  0,  ..., 12, 12, 12],\n",
      "          [ 0,  0,  0,  ..., 12, 12, 12],\n",
      "          ...,\n",
      "          [14, 14, 14,  ...,  8,  9, 10],\n",
      "          [14, 14, 14,  ...,  8,  9, 10],\n",
      "          [14, 14, 14,  ...,  8,  9, 10]],\n",
      "\n",
      "         [[ 0,  0,  0,  ..., 14, 14, 14],\n",
      "          [ 0,  0,  0,  ..., 14, 14, 14],\n",
      "          [ 0,  0,  0,  ..., 14, 14, 14],\n",
      "          ...,\n",
      "          [16, 16, 16,  ..., 13, 14, 14],\n",
      "          [16, 16, 16,  ..., 13, 14, 14],\n",
      "          [16, 16, 16,  ..., 13, 14, 14]],\n",
      "\n",
      "         [[37, 37, 37,  ..., 55, 55, 55],\n",
      "          [37, 37, 37,  ..., 55, 55, 55],\n",
      "          [37, 37, 37,  ..., 55, 55, 55],\n",
      "          ...,\n",
      "          [54, 54, 54,  ..., 35, 37, 39],\n",
      "          [54, 54, 54,  ..., 35, 37, 39],\n",
      "          [54, 54, 54,  ..., 35, 37, 39]]]], dtype=torch.uint8)\n",
      "(tensor(0.), tensor(0.))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torchmetrics.image.kid import KernelInceptionDistance\n",
    "kid = KernelInceptionDistance(subset_size=4)\n",
    "\n",
    "def load_and_convert_images(file_path):\n",
    "    img = Image.open(file_path).resize((480, 640))\n",
    "    img_array = np.array(img)\n",
    "    img_tensor = torch.tensor(img_array, dtype=torch.uint8)\n",
    "    img_tensor = img_tensor.permute(2, 0, 1)  # Ensure correct dimension order: channels, height, width\n",
    "    return img_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Define your images paths\n",
    "img1_path = \"./obamatest6.jpg\"\n",
    "img2_path = \"./zucktest3.jpeg\"\n",
    "\n",
    "# Load and convert images\n",
    "img1 = load_and_convert_images(img1_path)\n",
    "img2 = load_and_convert_images(img2_path)\n",
    "\n",
    "kid.update(img1, real=True)\n",
    "kid.update(img1, real=False)\n",
    "kid.update(img1, real=True)\n",
    "kid.update(img1, real=False)\n",
    "kid.update(img1, real=True)\n",
    "kid.update(img1, real=False)\n",
    "kid.update(img1, real=True)\n",
    "kid.update(img1, real=False)\n",
    "kid.update(img1, real=True)\n",
    "kid.update(img1, real=False)\n",
    "\n",
    "kid_mean, kid_std = kid.compute()\n",
    "print((kid_mean, kid_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cb190-b388-45a7-82ad-cc9fd7e16319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
